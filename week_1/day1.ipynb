{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2859571-2971-4199-91e9-df01c338f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d6a3e8-251a-42b0-9c91-2c4ce23b7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaconda environment is active:\n",
      "Environment Path: /home/hamna/miniconda3/envs/llms\n",
      "Environment Name: llms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "conda_prefix = os.environ.get('CONDA_PREFIX')\n",
    "if conda_prefix:\n",
    "    print(\"Anaconda environment is active:\")\n",
    "    print(f\"Environment Path: {conda_prefix}\")\n",
    "    print(f\"Environment Name: {os.path.basename(conda_prefix)}\")\n",
    "\n",
    "virtual_env = os.environ.get('VIRTUAL_ENV')\n",
    "if virtual_env:\n",
    "    print(\"Virtualenv is active:\")\n",
    "    print(f\"Environment Path: {virtual_env}\")\n",
    "    print(f\"Environment Name: {os.path.basename(virtual_env)}\")\n",
    "\n",
    "if not conda_prefix and not virtual_env:\n",
    "    print(\"Neither Anaconda nor Virtualenv seems to be active. Did you start jupyter lab in an Activated environment? See Setup Part 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0a06ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file found.\n",
      "SUCCESS! OPENAI_API_KEY found and it has the right prefix\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path(\"..\")\n",
    "env_path = parent_dir / \".env\"\n",
    "\n",
    "if env_path.exists() and env_path.is_file():\n",
    "    print(\".env file found.\")\n",
    "\n",
    "    # Read the contents of the .env file\n",
    "    with env_path.open(\"r\") as env_file:\n",
    "        contents = env_file.readlines()\n",
    "\n",
    "    key_exists = any(line.startswith(\"OPENAI_API_KEY=\") for line in contents)\n",
    "    good_key = any(line.startswith(\"OPENAI_API_KEY=sk-proj-\") for line in contents)\n",
    "    \n",
    "    if key_exists and good_key:\n",
    "        print(\"SUCCESS! OPENAI_API_KEY found and it has the right prefix\")\n",
    "    elif key_exists:\n",
    "        print(\"Found an OPENAI_API_KEY although it didn't have the expected prefix sk-proj- \\nPlease double check your key in the file..\")\n",
    "    else:\n",
    "        print(\"Didn't find an OPENAI_API_KEY in the .env file\")\n",
    "else:\n",
    "    print(\".env file not found in the llm_engineering directory. It needs to have exactly the name: .env\")\n",
    "    \n",
    "    possible_misnamed_files = list(parent_dir.glob(\"*.env*\"))\n",
    "    \n",
    "    if possible_misnamed_files:\n",
    "        print(\"\\nWarning: No '.env' file found, but the following files were found in the llm_engineering directory that contain '.env' in the name. Perhaps this needs to be renamed?\")\n",
    "        for file in possible_misnamed_files:\n",
    "            print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e58165-f279-4501-936f-f1751173c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51a41ea-d05d-423a-bdbc-8885146ee498",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fa0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3d202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "August 6, 2024\n",
      "Outsmart LLM Arena – a battle of diplomacy and deviousness\n",
      "June 26, 2024\n",
      "Choosing the Right LLM: Toolkit and Resources\n",
      "Navigation\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95588992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88911bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3716ed",
   "metadata": {},
   "source": [
    "```Python \n",
    "The API from OpenAI expects to receive messages in a particular structure. Many of the other APIs share this structure:\n",
    "\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cbda5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38d0b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nOctober 16, 2024\\nFrom Software Engineer to AI Data Scientist – resources\\nAugust 6, 2024\\nOutsmart LLM Arena – a battle of diplomacy and deviousness\\nJune 26, 2024\\nChoosing the Right LLM: Toolkit and Resources\\nNavigation\\nHome\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cca526",
   "metadata": {},
   "source": [
    "# Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f95f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2efd6fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Summary of Edward Donner\\'s Website\\n\\nThe website serves as a personal platform for Ed Donner, who is an experimental coder, DJ, and co-founder of Nebula.io. Ed focuses on leveraging AI technology, specifically large language models (LLMs), to enhance talent discovery and management. His background includes founding the AI startup untapt, which was acquired in 2021.\\n\\nThe site features a section called **Outsmart**, designed as a competitive arena where LLMs engage in challenges related to diplomacy and strategic thinking. \\n\\n## Recent Posts and Announcements\\n- **November 13, 2024:** \"Mastering AI and LLM Engineering – Resources\"\\n- **October 16, 2024:** \"From Software Engineer to AI Data Scientist – resources\"\\n- **August 6, 2024:** \"Outsmart LLM Arena – a battle of diplomacy and deviousness\"\\n- **June 26, 2024:** \"Choosing the Right LLM: Toolkit and Resources\"\\n\\nThese posts provide resources and insights into AI, LLMs, and professional development in the tech field.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8cda604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49004dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Hassan-Javed Website\n",
       "\n",
       "Hassan-Javed is a personal website of an AI Developer based in Pakistan, specializing in machine learning, deep learning, and natural language processing (NLP). With over three years of professional experience in AI and a robust programming background in Python, Hassan Javed emphasizes his dedication to developing AI-driven solutions that advance organizational goals. \n",
       "\n",
       "## About Me\n",
       "- **Education**: Currently pursuing an MS in Data Science and holds a Bachelor's degree in Computer Science.\n",
       "- **Experience**: Over three years in AI-focused roles, with experience in both industry and research, including work with advanced models like Llama 3.2.\n",
       "\n",
       "## Skills\n",
       "- **Programming Languages**: Python, JavaScript, C/C++, PHP, HTML, CSS.\n",
       "- **Data Science & AI**: Proficient in machine learning techniques, computer vision, data analysis, and model optimization.\n",
       "- **Tools & Frameworks**: Experienced with TensorFlow, PyTorch, Flask, Django, and data visualization libraries like Matplotlib and Seaborn.\n",
       "\n",
       "## Services\n",
       "Hassan offers a range of services, including:\n",
       "- **AI & Machine Learning Development**: Advanced model implementation, particularly with Llama models.\n",
       "- **Data Science & Analytics**: In-depth data analysis, forecasting, and predictive modeling.\n",
       "- **Machine Learning Engineering**: Model deployment and optimization to enhance performance and explainability.\n",
       "\n",
       "## Experience\n",
       "The website details several roles held by Hassan, including:\n",
       "- **Current Role**: AI Developer at NASTP @ PAF, focused on research and development in AI, particularly in chatbots and time series models.\n",
       "- **Previous Roles**: Worked at PanaceaLogics, focusing on NLP solutions and data science applications. \n",
       "\n",
       "## Portfolio\n",
       "The portfolio section showcases various projects Hassan has worked on, indicating a strong capability in deploying functional, innovative applications, notably in AI.\n",
       "\n",
       "## Blog\n",
       "The blog features posts related to branding and design, focusing on the significance of web design in enhancing business efficacy and user interaction.\n",
       "\n",
       "## Contact Information\n",
       "Hassan can be contacted via email, phone, or through the submission form on the website, with locations in Rawalpindi, Pakistan.\n",
       "\n",
       "This website serves as a professional showcase of Hassan Javed's expertise and services in the field of AI and machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://hassan883.github.io/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df792dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Expertise:**\n",
      "1. Languages: Python, R, SQL\n",
      "2. Experience: Data analysis, Data visualization, Machine learning models development\n",
      "3. Years of experience in AI, ML, and DL: 5 years\n",
      "\n",
      "**Projects related to LLMs:**\n",
      "1. Developed a sentiment analysis model using LSTM for analyzing customer reviews in the e-commerce industry. \n",
      "3. Utilized NLP techniques for text summarization in a news aggregation platform.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"You work as an assitant, and your job is to convert the content into the markdown and list down the experties in langauges, experience, years of experience in AI, ML and DL or LLMs, and list down the project which is related to LLMs\"\n",
    "user_prompt = \"\"\"\n",
    "    your are looking at the personal site and look for the list of information from the site, and ignores the, blogs and contact information. \n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\",\"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages= messages\n",
    ")\n",
    "\n",
    "# Step 4: print the result\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768c2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
